# Agentic RAG Pipeline: Deep Technical Guide

## Table of Contents
1. [Core Concepts](#core-concepts)
2. [Architecture Deep Dive](#architecture-deep-dive)
3. [Key Components](#key-components)
4. [Tradeoffs & Design Decisions](#tradeoffs--design-decisions)
5. [Implementation Guide](#implementation-guide)
6. [Advanced Patterns](#advanced-patterns)

---

## Core Concepts

### What is Agentic RAG?

**Traditional RAG**: Query ‚Üí Retrieve ‚Üí Generate  
**Agentic RAG**: Query ‚Üí **Agent Plans** ‚Üí Multi-step Retrieval ‚Üí Reasoning ‚Üí Generate

The key difference: **autonomy and decision-making**. An agentic system can:
- Decide *when* to retrieve
- Choose *what* to retrieve from multiple sources
- Perform *multi-hop* reasoning
- Self-correct and iterate
- Use tools beyond just vector search

### Why Agentic?

Traditional RAG assumes one retrieval step suffices. Real-world queries often need:
- **Decomposition**: "Compare X and Y" ‚Üí retrieve X, retrieve Y, compare
- **Iterative refinement**: Initial results insufficient ‚Üí reformulate ‚Üí retrieve again
- **Multi-source**: SQL databases + vector stores + APIs + web search
- **Reasoning chains**: Connect information across multiple documents

---

## Architecture Deep Dive

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USER QUERY                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AGENT ORCHESTRATOR                        ‚îÇ
‚îÇ  - Query understanding                                       ‚îÇ
‚îÇ  - Task decomposition                                        ‚îÇ
‚îÇ  - Planning (ReAct, Chain-of-Thought)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ              ‚îÇ              ‚îÇ
        ‚ñº              ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Vector DB  ‚îÇ ‚îÇ  SQL/Graph  ‚îÇ ‚îÇ  Tool APIs  ‚îÇ
‚îÇ   Retrieval ‚îÇ ‚îÇ   Queries   ‚îÇ ‚îÇ  (Search)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ               ‚îÇ               ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    REASONING ENGINE                          ‚îÇ
‚îÇ  - Context synthesis                                         ‚îÇ
‚îÇ  - Evidence evaluation                                       ‚îÇ
‚îÇ  - Contradiction detection                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  RESPONSE GENERATOR                          ‚îÇ
‚îÇ  - Grounded generation                                       ‚îÇ
‚îÇ  - Citation management                                       ‚îÇ
‚îÇ  - Confidence scoring                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Architectural Patterns

**1. ReAct (Reasoning + Acting)**
```
Thought: I need to find X
Action: search_vector_db("X")
Observation: [results about X]
Thought: Now I need Y to compare
Action: search_vector_db("Y")
Observation: [results about Y]
Thought: I have enough information
Action: generate_response()
```

**2. Plan-and-Execute**
- Generate full plan upfront
- Execute steps sequentially
- Less flexible but more predictable

**3. Hierarchical Agent**
- Meta-agent coordinates sub-agents
- Each sub-agent specializes (retrieval, reasoning, validation)

---

## Key Components

### 1. Agent Orchestrator

**Responsibilities:**
- Query parsing and intent classification
- Tool selection and sequencing
- State management across steps
- Error handling and recovery

**Implementation choices:**

| Approach | Pros | Cons | Best For |
|----------|------|------|----------|
| LLM-based (GPT-4, Claude) | Flexible, handles novel queries | Expensive, latency, non-deterministic | Complex reasoning |
| Programmatic rules | Fast, predictable, cheap | Brittle, limited flexibility | Well-defined domains |
| Hybrid | Balance flexibility/cost | More complex to maintain | Production systems |

**Key decision**: How much autonomy?
- **High autonomy**: Agent decides everything (tools, order, when to stop)
- **Low autonomy**: Predefined workflows with agent filling parameters
- **Tradeoff**: Flexibility vs. reliability/cost

### 2. Retrieval Layer

**Multi-modal retrieval strategies:**

**a) Dense Retrieval (Vector Search)**
```python
# Semantic similarity
embedding = embed(query)
results = vector_db.similarity_search(embedding, k=10)
```
- **Pros**: Semantic understanding, handles paraphrasing
- **Cons**: Struggles with exact matches, keyword-specific queries
- **When**: Conceptual questions, fuzzy matching

**b) Sparse Retrieval (BM25, Elasticsearch)**
```python
# Keyword matching with TF-IDF weighting
results = bm25.search(query, k=10)
```
- **Pros**: Fast, exact keyword matching, explainable
- **Cons**: No semantic understanding, vocabulary mismatch
- **When**: Specific terms, names, codes, IDs

**c) Hybrid Retrieval**
```python
# Combine both with reciprocal rank fusion
dense_results = vector_search(query)
sparse_results = bm25_search(query)
final_results = rerank(dense_results + sparse_results)
```
- **Pros**: Best of both worlds
- **Cons**: More complex, slower
- **When**: Production systems needing robustness

**d) Graph-based Retrieval**
- Query knowledge graphs for structured relationships
- Useful for multi-hop questions: "Who founded the company that acquired X?"

### 3. Reasoning Engine

**Core capabilities:**

**a) Multi-document synthesis**
```python
# Pseudo-code
def synthesize(documents, query):
    # Extract relevant passages per document
    passages = [extract_relevant(doc, query) for doc in documents]
    
    # Find supporting/contradicting evidence
    evidence_map = cluster_by_stance(passages)
    
    # Resolve contradictions
    resolved = resolve_conflicts(evidence_map)
    
    return synthesize_coherent_answer(resolved)
```

**b) Chain-of-thought reasoning**
- Break complex queries into logical steps
- Track intermediate conclusions
- Build evidence chains

**c) Self-consistency checking**
- Generate multiple reasoning paths
- Vote/aggregate across paths
- Increase confidence in final answer

### 4. Context Management

**The token budget problem:**

| Strategy | Description | Pros | Cons |
|----------|-------------|------|------|
| Truncation | Keep top-k chunks | Simple | Loses information |
| Summarization | Compress chunks | Preserves meaning | Adds latency, cost |
| Iterative refinement | Multiple LLM calls with pruning | Efficient token use | Complex, many API calls |
| Hierarchical chunking | Parent-child relationships | Maintains context | Requires careful indexing |

**Smart context packing:**
```python
def pack_context(chunks, max_tokens):
    # Prioritize by:
    # 1. Relevance score
    # 2. Diversity (avoid redundancy)
    # 3. Recency (for time-sensitive data)
    
    packed = []
    token_count = 0
    seen_topics = set()
    
    for chunk in sorted(chunks, key=relevance_score, reverse=True):
        if token_count + chunk.tokens > max_tokens:
            break
        if chunk.topic not in seen_topics:  # Diversity
            packed.append(chunk)
            token_count += chunk.tokens
            seen_topics.add(chunk.topic)
    
    return packed
```

---

## Tradeoffs & Design Decisions

### 1. Autonomy vs. Control

**High Autonomy (Agent-driven)**
```
‚úÖ Handles unexpected queries
‚úÖ Adapts to new situations
‚úÖ Multi-step reasoning
‚ùå Unpredictable behavior
‚ùå Higher cost (more LLM calls)
‚ùå Harder to debug
‚ùå Potential for loops/errors
```

**Low Autonomy (Workflow-driven)**
```
‚úÖ Predictable, reliable
‚úÖ Lower cost
‚úÖ Easier to debug
‚úÖ Faster (fewer LLM calls)
‚ùå Brittle to novel queries
‚ùå Limited flexibility
‚ùå Requires manual workflow design
```

**Recommendation**: Start with low autonomy for well-defined use cases, add autonomy where needed.

### 2. Retrieval Strategy

**Dense-only (Vector search)**
- **Use when**: Semantic/conceptual queries, user questions in natural language
- **Avoid when**: Exact match needed (IDs, codes), keyword-specific

**Sparse-only (BM25)**
- **Use when**: Keyword search, exact terms matter, low-latency needed
- **Avoid when**: Paraphrasing, synonyms, conceptual queries

**Hybrid (Recommended for production)**
- **Use when**: Need robustness across query types
- **Cost**: ~1.5-2x retrieval latency, more infrastructure

### 3. Reranking

**Should you rerank?**

```python
# Without reranking
results = vector_db.search(query, k=10)
context = results  # Use top 10 directly

# With reranking
candidates = vector_db.search(query, k=100)  # Get more candidates
results = reranker.rerank(candidates, query, k=10)  # Rerank to top 10
context = results
```

**Tradeoffs:**

| Aspect | Without Reranking | With Reranking |
|--------|-------------------|----------------|
| Latency | 50-100ms | 200-500ms |
| Accuracy | Good | Better (10-20% improvement) |
| Cost | Low | Medium (reranker API calls) |
| Complexity | Simple | Additional service |

**When to rerank:**
- High-stakes applications (medical, legal, financial)
- Poor initial retrieval quality
- Cross-encoder models (Cohere, Jina) significantly outperform embedding similarity

### 4. Chunking Strategy

**Fixed-size chunks**
```python
# Simple but crude
chunks = [text[i:i+512] for i in range(0, len(text), 512)]
```
- ‚úÖ Simple, fast
- ‚ùå Breaks mid-sentence, loses context

**Semantic chunking**
```python
# Split by paragraphs, sections
chunks = split_by_structure(text)
```
- ‚úÖ Preserves logical units
- ‚úÖ Better for QA
- ‚ùå Variable sizes (padding issues)

**Overlapping chunks**
```python
# 512 tokens, 50 token overlap
chunks = sliding_window(text, size=512, overlap=50)
```
- ‚úÖ Captures context across boundaries
- ‚ùå Storage overhead
- ‚ùå Redundancy in retrieval

**Hierarchical chunks**
```
Document ‚Üí Sections ‚Üí Paragraphs
Parent chunks (summaries) ‚Üí Child chunks (details)
```
- ‚úÖ Best for long documents
- ‚úÖ Retrieve summaries, fetch details on demand
- ‚ùå Complex indexing

### 5. When to Stop Retrieving?

**Fixed iterations** (e.g., always 3 retrieval steps)
- Predictable, simple
- May over/under-retrieve

**Confidence-based**
```python
if confidence_score(current_context) > threshold:
    stop()
```
- Adaptive
- Requires good confidence calibration

**Coverage-based**
```python
if query_terms_covered(context) >= 0.9:
    stop()
```
- Ensures completeness
- May miss semantic coverage

---

## Implementation Guide

### Phase 1: Simple Agentic RAG (2-3 days)

**Stack:**
- LLM: OpenAI GPT-4 or Anthropic Claude
- Vector DB: Pinecone, Weaviate, or Qdrant
- Framework: LangChain or LlamaIndex

**Architecture:**
```python
class SimpleAgenticRAG:
    def __init__(self, vector_db, llm):
        self.vector_db = vector_db
        self.llm = llm
        self.max_iterations = 3
    
    def run(self, query):
        context = []
        
        for i in range(self.max_iterations):
            # Agent decides what to do
            action = self.llm.decide_action(query, context)
            
            if action.type == "retrieve":
                # Execute retrieval
                results = self.vector_db.search(action.search_query)
                context.extend(results)
            
            elif action.type == "answer":
                # Generate final answer
                return self.llm.generate(query, context)
        
        # Fallback if max iterations reached
        return self.llm.generate(query, context)
```

**Prompt for agent:**
```
You are a research assistant. Given a query and current context, decide:

1. "RETRIEVE: <search query>" - if you need more information
2. "ANSWER" - if you have enough information

Query: {query}
Current context: {context}
Decision:
```

### Phase 2: Multi-Tool Agentic RAG (1 week)

Add multiple retrieval sources:

```python
class MultiToolAgenticRAG:
    def __init__(self, tools):
        self.tools = {
            "vector_search": VectorSearchTool(),
            "sql_query": SQLQueryTool(),
            "web_search": WebSearchTool(),
            "code_search": CodeSearchTool()
        }
        self.llm = ChatOpenAI()
    
    def run(self, query):
        # ReAct loop
        state = {"query": query, "context": [], "iterations": 0}
        
        while state["iterations"] < 10:
            # Agent thinks and acts
            thought, action, action_input = self.llm.think_and_act(state)
            
            if action == "final_answer":
                return self.llm.generate_answer(state)
            
            # Execute tool
            observation = self.tools[action].run(action_input)
            state["context"].append(observation)
            state["iterations"] += 1
        
        return self.llm.generate_answer(state)
```

**Tool descriptions for LLM:**
```python
tools = [
    {
        "name": "vector_search",
        "description": "Search internal documents by semantic similarity. Use for conceptual questions.",
        "parameters": {"query": "string"}
    },
    {
        "name": "sql_query",
        "description": "Query structured database. Use for specific data points, metrics, aggregations.",
        "parameters": {"sql": "string"}
    },
    {
        "name": "web_search",
        "description": "Search the web for current information. Use when internal docs insufficient.",
        "parameters": {"query": "string"}
    }
]
```

### Phase 3: Production-Grade (2-3 weeks)

**Key additions:**

1. **Guardrails**
```python
class Guardrails:
    def validate_query(self, query):
        # Check for PII, malicious input
        if self.contains_pii(query):
            raise ValueError("PII detected")
    
    def validate_tool_call(self, tool, params):
        # Prevent SQL injection, unsafe operations
        if tool == "sql_query":
            self.validate_sql(params["sql"])
    
    def validate_output(self, output):
        # Check for hallucinations, toxic content
        if self.is_hallucinated(output):
            return self.regenerate_with_stricter_grounding()
```

2. **Observability**
```python
@trace
def agent_step(self, state):
    # Log every agent decision
    logger.info({
        "iteration": state["iterations"],
        "thought": state["thought"],
        "action": state["action"],
        "tool_latency_ms": latency,
        "tokens_used": tokens
    })
```

3. **Caching**
```python
class CachedRetrieval:
    def __init__(self, vector_db):
        self.vector_db = vector_db
        self.cache = LRUCache(maxsize=1000)
    
    @cache
    def search(self, query):
        return self.vector_db.search(query)
```

4. **Error handling**
```python
def robust_agent_loop(self, query):
    try:
        return self.agent_loop(query)
    except ToolTimeoutError:
        # Retry with different tool
        return self.fallback_retrieval(query)
    except ContextOverflowError:
        # Compress context
        return self.agent_loop_with_compression(query)
```

### Code Example: Full Implementation

```python
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum

class ActionType(Enum):
    RETRIEVE = "retrieve"
    QUERY_SQL = "query_sql"
    WEB_SEARCH = "web_search"
    ANSWER = "answer"

@dataclass
class AgentAction:
    type: ActionType
    params: Dict[str, Any]
    reasoning: str

class AgenticRAG:
    def __init__(self, llm, vector_db, sql_db):
        self.llm = llm
        self.vector_db = vector_db
        self.sql_db = sql_db
        self.max_iterations = 5
    
    def run(self, query: str) -> str:
        state = {
            "query": query,
            "context": [],
            "thought_chain": [],
            "iteration": 0
        }
        
        while state["iteration"] < self.max_iterations:
            # Agent decides next action
            action = self._decide_action(state)
            state["thought_chain"].append(action.reasoning)
            
            if action.type == ActionType.ANSWER:
                return self._generate_answer(state)
            
            # Execute action
            observation = self._execute_action(action)
            state["context"].append({
                "action": action,
                "observation": observation
            })
            state["iteration"] += 1
        
        # Max iterations reached, generate best answer
        return self._generate_answer(state)
    
    def _decide_action(self, state: Dict) -> AgentAction:
        prompt = f"""
You are a research assistant using the ReAct framework.

Query: {state['query']}

Previous thoughts and actions:
{self._format_thought_chain(state['thought_chain'])}

Current context:
{self._format_context(state['context'])}

Decide your next action:
1. RETRIEVE <query> - Search vector database for relevant documents
2. QUERY_SQL <sql> - Execute SQL query on structured data
3. WEB_SEARCH <query> - Search the web for current information
4. ANSWER - You have enough information to answer

Format:
Thought: [Your reasoning]
Action: [Action type]
Input: [Action input]
"""
        
        response = self.llm.complete(prompt)
        return self._parse_action(response)
    
    def _execute_action(self, action: AgentAction) -> str:
        if action.type == ActionType.RETRIEVE:
            results = self.vector_db.search(
                action.params["query"],
                k=5
            )
            return self._format_retrieval_results(results)
        
        elif action.type == ActionType.QUERY_SQL:
            results = self.sql_db.execute(action.params["sql"])
            return str(results)
        
        elif action.type == ActionType.WEB_SEARCH:
            results = web_search(action.params["query"])
            return self._format_web_results(results)
    
    def _generate_answer(self, state: Dict) -> str:
        prompt = f"""
Based on the following context, answer the query.

Query: {state['query']}

Context:
{self._format_context(state['context'])}

Provide a comprehensive answer with citations.
"""
        return self.llm.complete(prompt)
    
    def _format_context(self, context: List[Dict]) -> str:
        formatted = []
        for i, item in enumerate(context):
            formatted.append(
                f"[{i+1}] Action: {item['action'].type.value}\n"
                f"    Result: {item['observation'][:200]}..."
            )
        return "\n".join(formatted)

# Usage
rag = AgenticRAG(
    llm=ChatGPT4(),
    vector_db=PineconeDB(),
    sql_db=PostgreSQL()
)

answer = rag.run("What were our Q3 sales compared to last year?")
```

---

## Advanced Patterns

### 1. Self-Correcting Retrieval

Agent critiques its own retrievals:

```python
def self_correcting_retrieval(self, query, max_attempts=3):
    for attempt in range(max_attempts):
        results = self.retrieve(query)
        
        # Agent evaluates quality
        critique = self.llm.evaluate_retrieval(query, results)
        
        if critique.is_sufficient:
            return results
        
        # Reformulate based on critique
        query = self.llm.reformulate(query, critique.issues)
    
    return results  # Return best attempt
```

### 2. Multi-Agent Collaboration

```python
class MultiAgentRAG:
    def __init__(self):
        self.retrieval_agent = RetrievalAgent()
        self.reasoning_agent = ReasoningAgent()
        self.validation_agent = ValidationAgent()
    
    def run(self, query):
        # Retrieval agent gathers information
        context = self.retrieval_agent.gather(query)
        
        # Reasoning agent synthesizes
        draft_answer = self.reasoning_agent.synthesize(query, context)
        
        # Validation agent checks
        validation = self.validation_agent.validate(
            query, context, draft_answer
        )
        
        if not validation.passed:
            # Retry with feedback
            context += self.retrieval_agent.gather(
                query, feedback=validation.issues
            )
            draft_answer = self.reasoning_agent.synthesize(query, context)
        
        return draft_answer
```

### 3. Graph-based RAG

For multi-hop reasoning:

```python
class GraphRAG:
    def __init__(self, knowledge_graph, vector_db):
        self.kg = knowledge_graph
        self.vector_db = vector_db
    
    def multi_hop_query(self, query):
        # Extract entities
        entities = self.extract_entities(query)
        
        # Traverse graph
        subgraph = self.kg.get_subgraph(
            entities,
            hops=2
        )
        
        # Get detailed info for relevant nodes
        detailed_info = []
        for node in subgraph.important_nodes():
            docs = self.vector_db.search(f"information about {node}")
            detailed_info.append(docs)
        
        # Combine graph structure + vector retrieval
        return self.synthesize(subgraph, detailed_info)
```

### 4. Streaming Responses

```python
async def streaming_agentic_rag(self, query):
    state = {"query": query, "context": []}
    
    async for event in self.agent_loop_async(state):
        if event.type == "thought":
            yield f"üí≠ Thinking: {event.content}\n"
        
        elif event.type == "action":
            yield f"üîß Action: {event.content}\n"
        
        elif event.type == "observation":
            yield f"üìÑ Found: {event.summary}\n"
        
        elif event.type == "answer":
            yield f"\nüìù Answer:\n{event.content}"
```

---

## Evaluation & Monitoring

### Key Metrics

**Retrieval Quality:**
- Precision@k: % of retrieved docs that are relevant
- Recall@k: % of relevant docs that are retrieved
- MRR (Mean Reciprocal Rank): Position of first relevant doc

**Agent Behavior:**
- Average iterations per query
- Tool usage distribution
- Success rate (query answered vs. failed)
- Cost per query (tokens, API calls)

**Answer Quality:**
- Faithfulness: Answer grounded in context?
- Relevance: Addresses the query?
- Coherence: Logically consistent?

### Evaluation Framework

```python
class RAGEvaluator:
    def evaluate_batch(self, test_cases):
        results = []
        
        for test in test_cases:
            output = self.rag.run(test.query)
            
            metrics = {
                "retrieval_precision": self.eval_retrieval(
                    output.retrieved_docs,
                    test.relevant_docs
                ),
                "answer_faithfulness": self.eval_faithfulness(
                    output.answer,
                    output.context
                ),
                "answer_relevance": self.eval_relevance(
                    output.answer,
                    test.query
                ),
                "iterations": output.iterations,
                "cost": output.total_cost
            }
            
            results.append(metrics)
        
        return self.aggregate_metrics(results)
```

---

## Common Pitfalls & Solutions

### 1. Infinite Loops
**Problem**: Agent keeps retrieving without stopping
**Solution**: Hard iteration limits, confidence-based stopping, detect repetitive actions

### 2. Context Overflow
**Problem**: Too much retrieved content, exceeds token limit
**Solution**: Aggressive reranking, summarization, hierarchical retrieval

### 3. Hallucination
**Problem**: Agent makes up information not in context
**Solution**: Strict grounding, citation requirements, validation agent

### 4. High Cost
**Problem**: Too many LLM calls, expensive per query
**Solution**: Caching, cheaper models for planning, reduce iterations

### 5. Latency
**Problem**: Multiple sequential tool calls = slow
**Solution**: Parallel retrieval where possible, caching, async execution

---

## Further Reading

**Papers:**
- "ReAct: Synergizing Reasoning and Acting in Language Models"
- "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"
- "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"

**Frameworks:**
- LangGraph (for complex agent workflows)
- LlamaIndex (RAG-focused)
- Semantic Kernel (Microsoft's agentic framework)

**Tools:**
- Vector DBs: Pinecone, Weaviate, Qdrant, Chroma
- Rerankers: Cohere Rerank, Jina Reranker
- Observability: LangSmith, Weights & Biases

---

## Quick Start Checklist

- [ ] Define your use case and query patterns
- [ ] Choose autonomy level (high vs. low)
- [ ] Set up vector database and indexing
- [ ] Implement simple ReAct loop
- [ ] Add multiple retrieval tools
- [ ] Implement guardrails and validation
- [ ] Add observability and logging
- [ ] Create evaluation dataset
- [ ] Optimize based on metrics
- [ ] Deploy with monitoring

Good luck building! Start simple, iterate based on real queries, and add complexity only where needed.
